{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, reading the data from the pre-trained GloVe Word Embeddings into <code>words</code> and <code>vecs</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = []\n",
    "        vecs = []\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            words.append(line[0])\n",
    "            vecs.append(np.array(line[1:], dtype=np.float64))\n",
    "    return words, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, vecs = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting <code>words</code> and <code>vecs</code> using <code>key = words</code> in order to use binary search later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec = zip(words, vecs)\n",
    "wordvec = sorted(wordvec, key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('!', array([-0.58402 ,  0.39031 ,  0.65282 , -0.3403  ,  0.19493 , -0.83489 ,\n",
       "         0.11929 , -0.57291 , -0.56844 ,  0.72989 , -0.56975 ,  0.53436 ,\n",
       "        -0.38034 ,  0.22471 ,  0.98031 , -0.2966  ,  0.126   ,  0.55222 ,\n",
       "        -0.62737 , -0.082242, -0.085359,  0.31515 ,  0.96077 ,  0.31986 ,\n",
       "         0.87878 , -1.5189  , -1.7831  ,  0.35639 ,  0.9674  , -1.5497  ,\n",
       "         2.335   ,  0.8494  , -1.2371  ,  1.0623  , -1.4267  , -0.49056 ,\n",
       "         0.85465 , -1.2878  ,  0.60204 , -0.35963 ,  0.28586 , -0.052162,\n",
       "        -0.50818 , -0.63459 ,  0.33889 ,  0.28416 , -0.2034  , -1.2338  ,\n",
       "         0.46715 ,  0.78858 ]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [i[0] for i in wordvec ]\n",
    "vecs = [i[1] for i in wordvec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 400000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words), len(vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting <code>vecs</code> to numpy array for better access and usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs = np.array(vecs)\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Binary Search in <code>list</code> of <code>words</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(wrd, arr):\n",
    "    low = 0\n",
    "    high = len(arr)-1\n",
    "    while low <= high:\n",
    "        mid = (low + high)//2\n",
    "        if arr[mid]==wrd:\n",
    "            return mid\n",
    "        if arr[mid] < wrd:\n",
    "            low = mid+1\n",
    "        if arr[mid] > wrd:\n",
    "            high = mid-1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233026"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('mango', words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity function returning similarity of a single vector with all word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(u, v):\n",
    "    num = np.dot(u, v.T).reshape((u.shape[0], 1))\n",
    "    den = (np.linalg.norm(u, axis=1)*np.linalg.norm(v, axis=1)).reshape((u.shape[0], 1))\n",
    "    sim = num/den\n",
    "    return sim.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(vecs, np.ones((1,50))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the similarity values mask out the indices with similarity > 0.7 and return those words as <code>(word, similarity_value)</code> pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(word, words, vecs):\n",
    "    idx = search(word, words)\n",
    "    if idx==-1:\n",
    "        return \"Word not in vocabulary!\"\n",
    "    vec1 = vecs[idx].reshape((1,50))\n",
    "    sims = similarity(vecs, vec1)\n",
    "    simidx = np.where(sims > 0.7)[0]\n",
    "    simwords = []\n",
    "    for i in simidx:\n",
    "        simwords.append((words[i], sims[i]))\n",
    "    return simwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the resulting similar words by descending order of similarity and return top 5 similar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_results(simwords):\n",
    "    if simwords==\"Word not in vocabulary!\":\n",
    "        return simwords\n",
    "    simwords = sorted(simwords, key = lambda x:x[1], reverse=True)\n",
    "    return list(np.array(simwords)[:5,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india', 'indian', 'pakistan', 'malaysia', 'bangladesh']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_results(find_similar('india', words, vecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save <code>vecs</code> into a <i>.npy</i> file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('vecs.npy', vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the <code>words</code> into a binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "with open('words.dat', 'wb') as f:\n",
    "    dump(words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
